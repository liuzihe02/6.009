{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators\n",
    "\n",
    "Generators are functions that return a list of values to iterate over. Rather than constructing the whole list, we create and return one element at a time. This can often be faster and more space efficient. If we are looking for an element that meets some criteria, we can't break and don't have to create every single element. Since we are only making one element at a time, we avoid having to make a massive list that could give us a MemoryError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two key words used in generators. The first is `yield` which on iteration will return a value and halt at that point. When we need the next value on the next iteration we will continue from that point. The second is `yield from` which, when called on an iterable (list, set, another generator) will continually yield everything from it one at a time before commencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_range(n):\n",
    "    counter = 0\n",
    "    while counter <= n:\n",
    "        yield counter\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for elem in generate_range(10):\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generators can also recursive. In the example before we yield from the recursive results before yielding the value for the current iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_range(n):\n",
    "    if n > 0:\n",
    "        yield from generate_range(n-1)\n",
    "    yield n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for elem in generate_range(10):\n",
    "    print (elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because generators do not evaluate all of the values at once, they are not indexable. It is possible to convert them into a list by passing it into the constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object generate_range at 0x7f41bd1f21f0>\n"
     ]
    }
   ],
   "source": [
    "print (generate_range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mgenerate_range\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print (generate_range(10)[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print (list(generate_range(10)))\n",
    "print (list(generate_range(10))[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding all Subsets\n",
    "\n",
    "Below are two implementations of finding all of the subsets of a list. The first, `get_all_subsets`, creates a list of the result and is a recursive function similar to what you've seen before. The second, `generate_all_subsets`, is the generator equivalent for it.\n",
    "\n",
    "As the number of elements grows, the number of elements gets incredibly large. If we make a giant list, it may be too big to fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subsets(elements, current_index=0, current_subset=None):\n",
    "    results = []\n",
    "    if current_subset is None:\n",
    "        current_subset = []\n",
    "    if current_index < len(elements):\n",
    "        current_element = elements[current_index]\n",
    "        # add current element to subset\n",
    "        results.extend(get_all_subsets(elements, current_index+1, current_subset + [current_element]))\n",
    "        # skip current element\n",
    "        results.extend(get_all_subsets(elements, current_index+1, current_subset))\n",
    "    else:\n",
    "#         print (\"appending: {}\".format(current_subset))\n",
    "        results.append(current_subset)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [1, 2], [1, 3], [1], [2, 3], [2], [3], []]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_subsets([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_all_subsets([1,2,3,4,5,6,7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_all_subsets(list(range(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_all_subsets(list(range(20))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_all_subsets(elements, current_index=0, current_subset=None):\n",
    "    if current_subset is None:\n",
    "        current_subset = []\n",
    "    if current_index < len(elements):\n",
    "        current_element = elements[current_index]\n",
    "        # add current element to subset\n",
    "        yield from generate_all_subsets(elements, current_index+1, current_subset + [current_element])\n",
    "        # skip current element\n",
    "        yield from generate_all_subsets(elements, current_index+1, current_subset)\n",
    "    else:\n",
    "        print (\"yielding: {}\".format(current_subset))\n",
    "        yield current_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yielding: [1, 2, 3]\n",
      "next: [1, 2, 3]\n",
      "yielding: [1, 2]\n",
      "next: [1, 2]\n",
      "yielding: [1, 3]\n",
      "next: [1, 3]\n",
      "yielding: [1]\n",
      "next: [1]\n",
      "yielding: [2, 3]\n",
      "next: [2, 3]\n",
      "yielding: [2]\n",
      "next: [2]\n",
      "yielding: [3]\n",
      "next: [3]\n",
      "yielding: []\n",
      "next: []\n"
     ]
    }
   ],
   "source": [
    "for element in generate_all_subsets(elements):\n",
    "    print (\"next:\", element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next: [1, 2, 3]\n",
      "next: [1, 2]\n",
      "next: [1, 3]\n",
      "next: [1]\n",
      "next: [2, 3]\n",
      "next: [2]\n",
      "next: [3]\n",
      "next: []\n"
     ]
    }
   ],
   "source": [
    "for element in get_all_subsets(elements):\n",
    "    print (\"next:\", element)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trie Items\n",
    "\n",
    "In Lab 5, we implemented a function to return all of the items in a Trie. It makes a lot of sense for this function to be a generator. Part of what makes a Trie useful is that it compresses words so we don't have to store all of them in their entirety. Making a giant list of the items will take up a lot of space. If we are looking for the first word with a particular value, we may not need to search through all the items in the Trie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trie:\n",
    "    def __init__(self, itemtype=None):\n",
    "        self.value = None\n",
    "        self.children = {}\n",
    "        self.type = itemtype\n",
    "\n",
    "    def checktype(self, key):\n",
    "        \"\"\"\n",
    "        Raise an error when a prefix of the wrong type is used\n",
    "        \"\"\"\n",
    "        if not isinstance(key, self.type):\n",
    "            raise TypeError\n",
    "\n",
    "    def getval(self, key):\n",
    "        \"\"\"\n",
    "        Helper for get and contains. Gets the value associated\n",
    "        with a key if one exists, otherwise returns None\n",
    "        \"\"\"\n",
    "        # Base case, traversed Trie down to the last element of the key\n",
    "        if len(key) == 0:\n",
    "            return self.value\n",
    "        # Recursive step: walk down Trie one element of key at a time\n",
    "        childKey = key[:1]\n",
    "        if childKey in self.children:\n",
    "            return self.children[childKey].getval(key[1:])\n",
    "        # If key does not exist in the Trie\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def set(self, key, value):\n",
    "        \"\"\"\n",
    "        Add a key with the given value to the trie, or reassign the associated\n",
    "        value if it is already present in the trie.  Assume that key is an\n",
    "        immutable ordered sequence.  Raise a TypeError if the given key is of\n",
    "        the wrong type.\n",
    "        \"\"\"\n",
    "        if self.type is None:\n",
    "            self.type = type(key)\n",
    "        else:\n",
    "            self.checktype(key)\n",
    "        # Iteratively travel down the trie one element of key at a time\n",
    "        current = self\n",
    "        for i in range(len(key)):\n",
    "            subkey = key[i:i+1]\n",
    "            if subkey not in current.children:\n",
    "                # Add a node for this key element if it doesn't already exist\n",
    "                if value is not None:\n",
    "                    current.children[subkey] = Trie(self.type)\n",
    "                else:\n",
    "                    # If we try to delete a key that doesn't exist in the Trie\n",
    "                    raise KeyError\n",
    "            current = current.children[subkey]\n",
    "        # Set the value for the node associated with the key\n",
    "        current.value = value\n",
    "\n",
    "\n",
    "    def get(self, key):\n",
    "        \"\"\"\n",
    "        Return the value for the specified prefix.  If the given key is not in\n",
    "        the trie, raise a KeyError.  If the given key is of the wrong type,\n",
    "        raise a TypeError.\n",
    "        \"\"\"\n",
    "        self.checktype(key)\n",
    "        val = self.getval(key)\n",
    "        if val is None:\n",
    "            raise KeyError\n",
    "        else:\n",
    "            return val\n",
    "\n",
    "    def delete(self, key):\n",
    "        \"\"\"\n",
    "        Delete the given key from the trie if it exists.\n",
    "        \"\"\"\n",
    "        # Setting the value of the key to None is all we need\n",
    "        # to do to dissociate them in the Trie\n",
    "        self.set(key, None)\n",
    "\n",
    "    def contains(self, key):\n",
    "        \"\"\"\n",
    "        Is key a key in the trie? return True or False.\n",
    "        \"\"\"\n",
    "        return self.getval(key) is not None\n",
    "\n",
    "    def get_items(self):\n",
    "        \"\"\"\n",
    "        Returns a list of (key, value) pairs for all keys/values in this trie and\n",
    "        its children.\n",
    "        \"\"\"\n",
    "        # APPROACH: Recursively build up items from children\n",
    "        ans = []\n",
    "        # Base case: Found a Trie node associated with a value\n",
    "        if self.value is not None:\n",
    "            ans.append((self.type(), self.value))\n",
    "        # Recursive step: Get items from children and prepend the keys associated with\n",
    "        # the children to build up full sequences\n",
    "        for childkey in self.children:\n",
    "            for subitem, val in self.children[childkey].get_items():\n",
    "                ans.append((childkey+subitem, val))\n",
    "        return ans\n",
    "    \n",
    "    def generate_items(self):\n",
    "        \"\"\"\n",
    "        Returns a list of (key, value) pairs for all keys/values in this trie and\n",
    "        its children\n",
    "        \"\"\"\n",
    "        # Base case: Found a Trie node associated with a value\n",
    "        if self.value is not None:\n",
    "            yield (self.type(), self.value)\n",
    "        # Recursive step: Get items from children and prepend the keys associated with\n",
    "        # the children to build up full sequences\n",
    "        for childkey in self.children:\n",
    "            for subitem, val in self.children[childkey].generate_items():\n",
    "                yield childkey+subitem, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_tokenize import tokenize_sentences\n",
    "\n",
    "def make_word_trie(text):\n",
    "    \"\"\"\n",
    "    Given a piece of text as a single string, create a Trie whose keys are the\n",
    "    words in the text, and whose values are the number of times the associated\n",
    "    word appears in the text\n",
    "    \"\"\"\n",
    "    frequencies = {}\n",
    "    for sentence in tokenize_sentences(text):\n",
    "        for word in sentence.split():\n",
    "            if word not in frequencies:\n",
    "                frequencies[word] = 0\n",
    "            frequencies[word] += 1\n",
    "    t = Trie()\n",
    "    for word, freq in frequencies.items():\n",
    "        t.set(word, freq)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequent_words(trie, desired_frequency, number_of_words):\n",
    "    \"\"\"\n",
    "    TODO Docstring\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    for item, freq in trie.get_items():\n",
    "        if freq > desired_frequency:\n",
    "            words.append(item)\n",
    "            if len(words) == number_of_words:\n",
    "                break\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_frequent_words(trie, desired_frequency, number_of_words):\n",
    "    \"\"\"\n",
    "    TODO Docstring\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    for item, freq in trie.generate_items():\n",
    "        if freq > desired_frequency:\n",
    "            words.append(item)\n",
    "            if len(words) == number_of_words:\n",
    "                break\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`make_word_trie` from the lab can be used to generate a mapping of words to frequencies. One thing we might care about is finding words that appear very frequently. We probably don't have to search through the entire Trie every time to do this. Using a generator instead of a list can make this faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Alice in Wonderland\n",
      "\n",
      "Non-Generator\n",
      "words seen more than 10 times: \t\t['project', 'poor', 'people', 'perhaps']\n",
      "words seen more than 100 times: \t['a', 'alice', 'all', 'and']\n",
      "words seen more than 1000 times: \t['the']\n",
      "words seen more than 100000 times: \t[]\n",
      "\n",
      "Genertor\n",
      "words seen more than 10 times: \t\t['project', 'poor', 'people', 'perhaps']\n",
      "words seen more than 100 times: \t['a', 'alice', 'all', 'and']\n",
      "words seen more than 1000 times: \t['the']\n",
      "words seen more than 100000 times: \t[]\n"
     ]
    }
   ],
   "source": [
    "filename = 'resources/alice.txt'\n",
    "with open(filename, encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "trie = make_word_trie(text)\n",
    "\n",
    "print (\"From Alice in Wonderland\\n\")\n",
    "\n",
    "print (\"Non-Generator\")\n",
    "print (\"words seen more than {} times: \\t\\t{}\".format(10, get_frequent_words(trie, 10, 4)))\n",
    "print (\"words seen more than {} times: \\t{}\".format(100, get_frequent_words(trie, 100, 4)))\n",
    "print (\"words seen more than {} times: \\t{}\".format(1000, get_frequent_words(trie, 1000, 4)))\n",
    "print (\"words seen more than {} times: \\t{}\\n\".format(100000, get_frequent_words(trie, 100000, 4)))\n",
    "\n",
    "print (\"Genertor\")\n",
    "print (\"words seen more than {} times: \\t\\t{}\".format(10, generate_frequent_words(trie, 10, 4)))\n",
    "print (\"words seen more than {} times: \\t{}\".format(100, generate_frequent_words(trie, 100, 4)))\n",
    "print (\"words seen more than {} times: \\t{}\".format(1000, generate_frequent_words(trie, 1000, 4)))\n",
    "print (\"words seen more than {} times: \\t{}\".format(100000, generate_frequent_words(trie, 100000, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'resources/lots_of_words.txt'\n",
    "with open(filename, encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "trie = make_word_trie(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words seen more than 1000 times: \n",
      "\tresult: \t['a', 'an', 'and', 'any', 'as', 'again', 'at', 'all', 'after', 'away']\n",
      "\ttime spent: \t0.1367 seconds\n",
      "\n",
      "10 words seen more than 10000 times: \n",
      "\tresult: \t['a', 'and', 'as', 'for', 'to', 'the', 'that', 'be', 'with', 'me']\n",
      "\ttime spent: \t0.1151 seconds\n",
      "\n",
      "10 words seen more than 100000 times: \n",
      "\tresult: \t[]\n",
      "\ttime spent: \t0.1204 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "frequent_words = get_frequent_words(trie, 1000, 10)\n",
    "end = time.time()\n",
    "print (\"{} words seen more than {} times: \\n\\tresult: \\t{}\\n\\ttime spent: \\t{:.4f} seconds\\n\".format(\n",
    "        10,\n",
    "        1000,\n",
    "        frequent_words,\n",
    "        end - start))\n",
    "\n",
    "start = time.time()\n",
    "frequent_words = get_frequent_words(trie, 10000, 10)\n",
    "end = time.time()\n",
    "print (\"{} words seen more than {} times: \\n\\tresult: \\t{}\\n\\ttime spent: \\t{:.4f} seconds\\n\".format(\n",
    "        10,\n",
    "        10000,\n",
    "        frequent_words,\n",
    "        end - start))\n",
    "\n",
    "start = time.time()\n",
    "frequent_words = get_frequent_words(trie, 100000, 10)\n",
    "end = time.time()\n",
    "print (\"{} words seen more than {} times: \\n\\tresult: \\t{}\\n\\ttime spent: \\t{:.4f} seconds\\n\".format(\n",
    "        10,\n",
    "        100000,\n",
    "        frequent_words,\n",
    "        end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 words seen more than 1000 times: \n",
      "\tresult: \t['a', 'an', 'and', 'any', 'as', 'again', 'at', 'all', 'after', 'away']\n",
      "\ttime spent: \t0.0042 seconds\n",
      "\n",
      "10 words seen more than 10000 times: \n",
      "\tresult: \t['a', 'and', 'as', 'for', 'to', 'the', 'that', 'be', 'with', 'me']\n",
      "\ttime spent: \t0.0314 seconds\n",
      "\n",
      "10 words seen more than 100000 times: \n",
      "\tresult: \t[]\n",
      "\ttime spent: \t0.1019 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "frequent_words = generate_frequent_words(trie, 1000, 10)\n",
    "end = time.time()\n",
    "print (\"{} words seen more than {} times: \\n\\tresult: \\t{}\\n\\ttime spent: \\t{:.4f} seconds\\n\".format(\n",
    "        10,\n",
    "        1000,\n",
    "        frequent_words,\n",
    "        end - start))\n",
    "\n",
    "start = time.time()\n",
    "frequent_words = generate_frequent_words(trie, 10000, 10)\n",
    "end = time.time()\n",
    "print (\"{} words seen more than {} times: \\n\\tresult: \\t{}\\n\\ttime spent: \\t{:.4f} seconds\\n\".format(\n",
    "        10,\n",
    "        10000,\n",
    "        frequent_words,\n",
    "        end - start))\n",
    "\n",
    "start = time.time()\n",
    "frequent_words = generate_frequent_words(trie, 100000, 10)\n",
    "end = time.time()\n",
    "print (\"{} words seen more than {} times: \\n\\tresult: \\t{}\\n\\ttime spent: \\t{:.4f} seconds\\n\".format(\n",
    "        10,\n",
    "        100000,\n",
    "        frequent_words,\n",
    "        end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
